# -*- coding: utf-8 -*-
"""CycleGAN (Resnet).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q5P21ROzJic1vjN66xuZqpzuRKjieyts
"""

import tensorflow as tf
import numpy as np
import tensorflow.keras as keras
import matplotlib.pyplot as plt
from IPython import display
import tensorflow_datasets as tfds

class Resnet(keras.layers.Layer):
  def __init__(self,filters,norm_layer):
    super(Resnet,self).__init__()
    self.norm_layer = norm_layer
    self.resnet = self.get_resnet(filters,norm_layer)

  def get_resnet(self,filters,norm_layer):
    block = []
    block+=[keras.layers.Conv2D(filters,3,padding='same'),
                  norm_layer(),
                  keras.layers.LeakyReLU(),
                  keras.layers.Dropout(0.2)]
    block+=[keras.layers.Conv2D(filters,3,padding='same'),
                  norm_layer(),
                  keras.layers.LeakyReLU(),
                  keras.layers.Dropout(0.2)]
    return keras.Sequential(block)

  def call(self,x,training=True):
    out = x+self.resnet(x,training=training)
    return out

class Generator(keras.Model):
  def __init__(self,output_dim=3,filters=64,norm_layer=keras.layers.BatchNormalization,n_blocks=6):
    super(Generator,self).__init__()

    gen = [keras.layers.Conv2D(filters,(7,7),padding='valid'),
           norm_layer(),
           keras.layers.LeakyReLU(),
           keras.layers.Dropout(0.2)]

    gen+=[keras.layers.Conv2D(filters*2,(3,3),strides=(2,2),padding='same'),
                norm_layer(),
                keras.layers.LeakyReLU(),
                keras.layers.Dropout(0.2)]

    gen+=[keras.layers.Conv2D(filters*4,(3,3),strides=(2,2),padding='same'),
                norm_layer(),
                keras.layers.LeakyReLU(),
                keras.layers.Dropout(0.2)]
    
    for i in range(n_blocks):
      gen+=[Resnet(256,norm_layer=norm_layer)]

    gen+=[keras.layers.Conv2DTranspose(256,(3,3),strides=(2,2),padding='same',output_padding=1),
                norm_layer(),
                keras.layers.LeakyReLU(),
                keras.layers.Dropout(0.2)]
    gen+=[keras.layers.ZeroPadding2D(padding=(2,2))]

    gen+=[keras.layers.Conv2DTranspose(512,(3,3),strides=(2,2),padding='same',output_padding=1),
                keras.layers.BatchNormalization(),
                keras.layers.LeakyReLU(),
                keras.layers.Dropout(0.2)]
    gen+=[keras.layers.ZeroPadding2D(padding=(1,1))]

    gen+=[keras.layers.Conv2D(output_dim,kernel_size=7,padding='valid',activation='tanh')]

    self.model = keras.Sequential(gen)
  
  def call(self,inputs,training=True):
    return self.model(inputs,training=training)

import tensorflow_addons as tfa

test_gen = Generator(norm_layer=tfa.layers.InstanceNormalization)

class Discriminator(keras.layers.Layer):
  def __init__(self,filters=64,norm_layer=keras.layers.BatchNormalization):
    super(Discriminator,self).__init__()

    disc=[keras.layers.Conv2D(filters,(4,4),strides=(2,2),padding='same'),
          keras.layers.LeakyReLU(0.2)]

    for i in range(3):
      disc+=[keras.layers.Conv2D(filters*(2**(i)),(4,4),strides=(2,2),padding='same'),
             norm_layer(),
             keras.layers.LeakyReLU(0.2)]
    
    disc+=[keras.layers.Conv2D(filters*8,(4,4),strides=(1,1),padding='same'),
           norm_layer(),
           keras.layers.LeakyReLU(0.2)]
    
    disc+=[keras.layers.Conv2D(1,(4,4),strides=(1,1),padding='same')]

    self.model = keras.Sequential(disc)
  
  def call(self,inputs,training=True):
    return self.model(inputs,training=training)

test_disc = Discriminator(norm_layer=tfa.layers.InstanceNormalization)

AUTOTUNE = tf.data.experimental.AUTOTUNE 
!pip install git+https://github.com/tensorflow/examples.git

dataset,metadata = tfds.load('cycle_gan/horse2zebra',with_info=True,as_supervised=True)
train_horses,train_zebras = dataset['trainA'],dataset['trainB']
test_horses,test_zebras = dataset['testA'],dataset['testB']

BUFFER_SIZE = 1000
BATCH_SIZE = 1
IMG_HEIGHT, IMG_WIDTH = 256, 256

@tf.function()
def random_jitter(image):
  image = tf.image.resize(image,[286,286],method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
  image = tf.image.random_crop(image,size=[IMG_HEIGHT,IMG_WIDTH,3])
  image = tf.image.random_flip_left_right(image)
  return image

def preprocess_image_train(image,label):
  image = random_jitter(image)
  image = tf.cast(image,tf.float32)
  image = (image/127.5)-1
  return image

def preprocess_image_test(image,label):
  image = tf.cast(image,tf.float32)
  image = (image/127.5)-1
  return image

train_horses = train_horses.map(preprocess_image_train,num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(1)
train_zebras = train_zebras.map(preprocess_image_train,num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(1)
test_horses = test_horses.map(preprocess_image_test,num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(1)
test_zebras = test_zebras.map(preprocess_image_test,num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(1)

sample_horse = next(iter(train_horses))
sample_zebra = next(iter(train_zebras))

to_zebra = test_gen(sample_horse)
to_horse = test_gen(sample_zebra)

print('to_zebra shape = ',to_zebra.shape,'\n')
print('to_horse shape = ',to_horse.shape,'\n')

plt.figure(figsize=(8,8))
contrast = 8
imgs = [sample_horse, to_zebra, sample_zebra, to_horse]
title = ['Horse', 'To Zebra', 'Zebra', 'To Horse']

for i in range(len(imgs)):
  plt.subplot(2, 2, i+1)
  plt.title(title[i])
  if i % 2 == 0:
    plt.imshow(imgs[i][0] * 0.5 + 0.5)
  else:
    plt.imshow(imgs[i][0] * 0.5 * contrast + 0.5)
plt.show()

bin_ce_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)
LAMBDA = 10

def discriminator_loss(real,generated):
  real_loss = bin_ce_loss(tf.ones_like(real),real)
  generated_loss = bin_ce_loss(tf.zeros_like(generated),generated)
  total_disc_loss = real_loss + generated_loss
  return total_disc_loss * 0.5

def generator_loss(generated):
  return bin_ce_loss(tf.ones_like(generated),generated)

def calculate_cycle_loss(real_img,cycled_img):
  loss = tf.reduce_mean(tf.abs(real_img-cycled_img))
  return LAMBDA*loss

def identity_loss(real,same):
  loss = tf.reduce_mean(tf.abs(real-same))
  return LAMBDA*0.5*loss

generator_g = Generator(norm_layer=tfa.layers.InstanceNormalization)
generator_f = Generator(norm_layer=tfa.layers.InstanceNormalization)

discriminator_x = Discriminator(norm_layer=tfa.layers.InstanceNormalization)
discriminator_y = Discriminator(norm_layer=tfa.layers.InstanceNormalization)

generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

EPOCHS = 40

def generate_images(model,input_img):
  prediction = model(input_img)
  plt.figure(figsize=(12,12))
  display_list = [input_img[0],prediction[0]]
  title = ['Input Image','Predicted Image']
  for i in range(2):
    plt.subplot(1,2,i+1)
    plt.title(title[i])
    plt.imshow(display_list[i]*0.5+0.5)
    plt.axis('off')
  plt.show()

@tf.function()
def train_step(real_x,real_y):
  with tf.GradientTape(persistent=True) as tape:

    fake_y = generator_g(real_x,training=True)

    cycled_x = generator_f(fake_y,training=True)

    fake_x = generator_f(real_y,training=True)

    cycled_y = generator_g(fake_x,training=True)

    same_x = generator_f(real_x,training=True)

    same_y = generator_g(real_y,training=True)

    disc_real_x = discriminator_x(real_x,training=True)

    disc_real_y = discriminator_y(real_y,training=True)

    disc_fake_x = discriminator_x(fake_x,training=True)

    disc_fake_y = discriminator_y(fake_y,training=True)

    generator_g_loss = generator_loss(disc_fake_y)
    generator_f_loss = generator_loss(disc_fake_x)

    total_cycle_loss = calculate_cycle_loss(real_x,cycled_x) + calculate_cycle_loss(real_y,cycled_y)

    total_generator_g_loss = generator_g_loss + total_cycle_loss + identity_loss(real_y,same_y)
    total_generator_f_loss = generator_f_loss + total_cycle_loss + identity_loss(real_x,same_x)

    discriminator_x_loss = discriminator_loss(disc_real_x,disc_fake_x)
    discriminator_y_loss = discriminator_loss(disc_real_y,disc_fake_y)

    generator_g_grads = tape.gradient(total_generator_g_loss,generator_g.trainable_variables)
    generator_f_grads = tape.gradient(total_generator_f_loss,generator_f.trainable_variables)

    discriminator_x_grads = tape.gradient(discriminator_x_loss,discriminator_x.trainable_variables)
    discriminator_y_grads = tape.gradient(discriminator_y_loss,discriminator_y.trainable_variables)

    generator_g_optimizer.apply_gradients(zip(generator_g_grads,generator_g.trainable_variables))
    generator_f_optimizer.apply_gradients(zip(generator_f_grads,generator_f.trainable_variables))

    discriminator_x_optimizer.apply_gradients(zip(discriminator_x_grads,discriminator_x.trainable_variables))
    discriminator_y_optimizer.apply_gradients(zip(discriminator_y_grads,discriminator_y.trainable_variables))

from IPython.display import clear_output
import time

for epoch in range(EPOCHS):
  start = time.time()
  n=0
  for image_x,image_y in tf.data.Dataset.zip((train_horses,train_zebras)):
    train_step(image_x,image_y)
    if n%10==0:
      print('.',end='')
    n+=1
  clear_output(wait=True)
  generate_images(generator_g,sample_horse)
  print('Time taken for epoch {} is {} sec\n'.format(epoch+1,time.time()-start))